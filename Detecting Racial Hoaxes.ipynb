{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, recall_score, precision_recall_curve, precision_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class RacialHoaxDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes=2):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.conv1 = nn.Conv1d(768, 128, kernel_size=3, padding=1)  # 768 is BERT hidden size\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state.permute(0, 2, 1)  # [batch, hidden_size, seq_len]\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class TransformerFFNNModel(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes=2):\n",
    "        super(TransformerFFNNModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=768, nhead=8, dim_feedforward=2048, dropout=0.1),\n",
    "            num_layers=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(768, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state  # [batch, seq_len, 768]\n",
    "        x = self.transformer(x)  # [batch, seq_len, 768]\n",
    "        x = x[:, 0, :]  # Use [CLS] token\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class RacialHoaxDetector:\n",
    "    def __init__(self, model_type='bert', label_column='labels'):\n",
    "        self.model_type = model_type\n",
    "        self.label_column = label_column\n",
    "        self.best_accuracy = 0.0\n",
    "\n",
    "        if model_type == 'bert':\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "            self.model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        elif model_type == 'xlm-roberta':\n",
    "            self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "            self.model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n",
    "        elif model_type == 'cnn':\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "            self.bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "            self.model = CNNModel(self.bert_model)\n",
    "        elif model_type == 'transformer-ffnn':\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "            self.bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "            self.model = TransformerFFNNModel(self.bert_model)\n",
    "\n",
    "        self.model.to(device)\n",
    "\n",
    "    def load_and_prepare_data(self, train_file, dev_file):\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        dev_df = pd.read_csv(dev_file)\n",
    "\n",
    "        if self.label_column not in train_df.columns:\n",
    "            raise KeyError(f\"Label column '{self.label_column}' not found in training data. Available columns: {train_df.columns}\")\n",
    "        if self.label_column not in dev_df.columns:\n",
    "            raise KeyError(f\"Label column '{self.label_column}' not found in dev data. Available columns: {dev_df.columns}\")\n",
    "\n",
    "        # Debug: Check label distribution\n",
    "        print(f\"Training label distribution:\\n{train_df[self.label_column].value_counts()}\")\n",
    "        print(f\"Validation label distribution:\\n{dev_df[self.label_column].value_counts()}\")\n",
    "\n",
    "        return train_df, dev_df\n",
    "\n",
    "    def create_dataloaders(self, train_df, dev_df, batch_size=16):\n",
    "        train_dataset = RacialHoaxDataset(\n",
    "            train_df['clean_text'].values,\n",
    "            train_df[self.label_column].values,\n",
    "            self.tokenizer\n",
    "        )\n",
    "        dev_dataset = RacialHoaxDataset(\n",
    "            dev_df['clean_text'].values,\n",
    "            dev_df[self.label_column].values,\n",
    "            self.tokenizer\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, dev_loader\n",
    "\n",
    "    def train_model(self, train_loader, dev_loader, epochs=3, learning_rate=2e-5):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=learning_rate if self.model_type in ['bert', 'xlm-roberta'] else 5e-4)\n",
    "        # Weighted loss to handle class imbalance\n",
    "        class_weights = torch.tensor([0.3, 0.7]).to(device)  # Adjust based on class distribution\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs} ({self.model_type})\")\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                if self.model_type in ['bert', 'xlm-roberta']:\n",
    "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "                else:\n",
    "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = nn.CrossEntropyLoss(weight=class_weights)(outputs, labels)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "            eval_results = self.evaluate_model(dev_loader, save_best=True)\n",
    "            accuracy, dev_loss, true_labels, predictions, probabilities, cm = eval_results\n",
    "            print(f\"Validation accuracy: {accuracy:.4f}, Validation loss: {dev_loss:.4f}\")\n",
    "\n",
    "    def evaluate_model(self, dev_loader, save_best=False):\n",
    "        self.model.eval()\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dev_loader, desc=\"Evaluating\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                if self.model_type in ['bert', 'xlm-roberta']:\n",
    "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "                    logits = outputs.logits\n",
    "                else:\n",
    "                    logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "                labels = labels.cpu().numpy()\n",
    "                probs = probs.cpu().numpy()[:, 1]\n",
    "\n",
    "                # Debug: Check predictions and probabilities\n",
    "                if len(set(preds)) == 1:\n",
    "                    print(f\"Warning: Model {self.model_type} predicts only one class: {set(preds)}\")\n",
    "                if np.any(np.isnan(probs)):\n",
    "                    print(f\"Warning: Model {self.model_type} produces NaN probabilities\")\n",
    "\n",
    "                predictions.extend(preds)\n",
    "                true_labels.extend(labels)\n",
    "                probabilities.extend(probs)\n",
    "                total_eval_accuracy += (preds == labels).mean()\n",
    "\n",
    "        avg_accuracy = total_eval_accuracy / len(dev_loader)\n",
    "        avg_loss = total_eval_loss / len(dev_loader)\n",
    "        cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "        if save_best and avg_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = avg_accuracy\n",
    "            self.save_model(f'best_model_{self.model_type}')\n",
    "            print(f\"New best model saved with accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = classification_report(true_labels, predictions, zero_division=0)\n",
    "        print(report)\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(f\"Model {self.model_type} predictions: {np.bincount(predictions)}\")\n",
    "\n",
    "        return avg_accuracy, avg_loss, true_labels, predictions, probabilities, cm\n",
    "\n",
    "    def predict(self, text):\n",
    "        self.model.eval()\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.model_type in ['bert', 'xlm-roberta']:\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "            else:\n",
    "                logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "            prediction = np.argmax(probs)\n",
    "\n",
    "        return prediction, probs\n",
    "\n",
    "    def save_model(self, output_dir):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        if self.model_type in ['bert', 'xlm-roberta']:\n",
    "            self.model.save_pretrained(output_dir)\n",
    "            self.tokenizer.save_pretrained(output_dir)\n",
    "        else:\n",
    "            torch.save(self.model.state_dict(), os.path.join(output_dir, 'model.pt'))\n",
    "        print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "    def save_predictions(self, dev_df, predictions, output_file):\n",
    "        dev_df['prediction'] = predictions\n",
    "        dev_df[['clean_text', self.label_column, 'prediction']].to_csv(output_file, index=False)\n",
    "        print(f\"Predictions saved to {output_file}\")\n",
    "        # Debug: Check prediction distribution\n",
    "        print(f\"Prediction distribution for {self.model_type}:\\n{pd.read_csv(output_file)['prediction'].value_counts()}\")\n",
    "\n",
    "def plot_metrics(models_results):\n",
    "    # Plot Confusion Matrices\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (model_name, results) in enumerate(models_results.items(), 1):\n",
    "        cm = results['confusion_matrix']\n",
    "        plt.subplot(2, 2, i)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrices.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot ROC Curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for model_name, results in models_results.items():\n",
    "        fpr, tpr, _ = roc_curve(results['true_labels'], results['probabilities'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('roc_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Precision-Recall Curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for model_name, results in models_results.items():\n",
    "        precision, recall, _ = precision_recall_curve(results['true_labels'], results['probabilities'])\n",
    "        plt.plot(recall, precision, label=f'{model_name}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('precision_recall_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Recall Comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    comparison_data = {\n",
    "        'Model': [],\n",
    "        'Recall': []\n",
    "    }\n",
    "    for model_name, results in models_results.items():\n",
    "        recall = recall_score(results['true_labels'], results['predictions'], zero_division=0)\n",
    "        comparison_data['Model'].append(model_name)\n",
    "        comparison_data['Recall'].append(recall)\n",
    "    recall_df = pd.DataFrame(comparison_data)\n",
    "    sns.barplot(x='Model', y='Recall', data=recall_df)\n",
    "    plt.title('Recall Comparison')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.savefig('recall_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Create Comparison Table and Report\n",
    "    comparison_data = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-Score': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "    report_lines = [\"Model Comparison Report\\n\" + \"=\"*50 + \"\\n\"]\n",
    "    for model_name, results in models_results.items():\n",
    "        accuracy = results['accuracy']\n",
    "        precision = precision_score(results['true_labels'], results['predictions'], zero_division=0)\n",
    "        recall = recall_score(results['true_labels'], results['predictions'], zero_division=0)\n",
    "        f1 = f1_score(results['true_labels'], results['predictions'], zero_division=0)\n",
    "        fpr, tpr, _ = roc_curve(results['true_labels'], results['probabilities'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        comparison_data['Model'].append(model_name)\n",
    "        comparison_data['Accuracy'].append(accuracy)\n",
    "        comparison_data['Precision'].append(precision)\n",
    "        comparison_data['Recall'].append(recall)\n",
    "        comparison_data['F1-Score'].append(f1)\n",
    "        comparison_data['AUC'].append(roc_auc)\n",
    "\n",
    "        report_lines.append(f\"Model: {model_name}\\n\")\n",
    "        report_lines.append(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "        report_lines.append(f\"Precision: {precision:.4f}\\n\")\n",
    "        report_lines.append(f\"Recall: {recall:.4f}\\n\")\n",
    "        report_lines.append(f\"F1-Score: {f1:.4f}\\n\")\n",
    "        report_lines.append(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "        report_lines.append(\"-\"*50 + \"\\n\")\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df.to_csv('model_comparison.csv', index=False)\n",
    "\n",
    "    # Save Comparison Report\n",
    "    with open('model_comparison_report.txt', 'w') as f:\n",
    "        f.writelines(report_lines)\n",
    "\n",
    "    # Plot Model Comparison\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.barplot(x='Model', y=metric, data=comparison_df)\n",
    "        plt.title(f'{metric} Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    model_types = ['bert', 'xlm-roberta', 'cnn', 'transformer-ffnn']\n",
    "    models_results = defaultdict(dict)\n",
    "\n",
    "    train_file = '/content/Racial_train.csv'\n",
    "    dev_file = '/content/Racial_val.csv'\n",
    "\n",
    "    for model_type in model_types:\n",
    "        print(f\"\\nTraining {model_type} model...\")\n",
    "        detector = RacialHoaxDetector(model_type=model_type, label_column='labels')\n",
    "        train_df, dev_df = detector.load_and_prepare_data(train_file, dev_file)\n",
    "        train_loader, dev_loader = detector.create_dataloaders(train_df, dev_df)\n",
    "\n",
    "        detector.train_model(train_loader, dev_loader)\n",
    "        accuracy, dev_loss, true_labels, predictions, probabilities, cm = detector.evaluate_model(dev_loader)\n",
    "\n",
    "        models_results[model_type] = {\n",
    "            'accuracy': accuracy,\n",
    "            'dev_loss': dev_loss,\n",
    "            'true_labels': true_labels,\n",
    "            'predictions': predictions,\n",
    "            'probabilities': probabilities,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "\n",
    "        detector.save_predictions(dev_df, predictions, f'predictions_{model_type}.csv')\n",
    "\n",
    "    plot_metrics(models_results)\n",
    "\n",
    "    # Example prediction\n",
    "    sample_text = \"ahamadtalwar ki nok par tumahre amao ne saya khol diya tha\"\n",
    "    detector = RacialHoaxDetector(model_type='bert', label_column='labels')\n",
    "    prediction, probability = detector.predict(sample_text)\n",
    "    print(f\"\\nSample Prediction:\")\n",
    "    print(f\"Text: {sample_text}\")\n",
    "    print(f\"Prediction: {'Racial Hoax' if prediction == 1 else 'Not Racial Hoax'}\")\n",
    "    print(f\"Confidence: {max(probability)*100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
